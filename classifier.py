# -*- coding: utf-8 -*-
"""Faces_Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dMa2a5dbTbGuZ0h2eBIDQXcnRyDL0TXq
"""

# Importing modules 
import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import cv2

from tensorflow.keras.utils import to_categorical
from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout
from keras.models import Sequential

from sklearn.model_selection import train_test_split

np.random.seed(1)


# Processing training data
# -> appending images in a list 'train_images'
# -> appending labels in a list 'train_labels'

train_images = []       
train_labels = []

train_path = './classifier_data/train_r'

for filename in os.listdir(train_path):
    if filename.split('.')[1] == 'jpg':
        img = cv2.imread(os.path.join(train_path,filename))
        # Spliting file names and storing the labels for image in list
        train_labels.append(filename.split('-')[0])
        train_images.append(img)

# Converting labels into One Hot encoded sparse matrix
train_labels = pd.get_dummies(train_labels).values

# Converting train_images to array
train_images = np.array(train_images)

# Splitting Training data into train and validation dataset
x_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)


# Processing testing data
# -> appending images in a list 'test_images'
# -> appending labels in a list 'test_labels'
# The test data contains labels as well also we are appending it to a list but we are'nt going to use it while training.

test_images = []
test_labels = []
test_path = './classifier_data/test_r'

for filename in os.listdir(test_path):
    if filename.split('.')[1] == 'jpg':
        img = cv2.imread(os.path.join(test_path,filename))
        
        # Spliting file names and storing the labels for image in list
        test_labels.append(filename.split('-')[0])
        test_images.append(img)
        
# Converting test_images to array
test_images = np.array(test_images)

# Visualizing Training data
print(train_labels[0])
plt.imshow(train_images[0])

# Creating a Sequential model
model= Sequential()
model.add(Conv2D(kernel_size=(3,3), filters=32, activation='relu', input_shape=(256,256,3,)))
model.add(Conv2D(filters=64,kernel_size = (3,3),activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Conv2D(filters=128,kernel_size = (3,3),activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Conv2D(filters=256,kernel_size = (3,3),activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Conv2D(filters=512,kernel_size = (3,3),activation='relu'))

model.add(Flatten())

model.add(Dense(20,activation='relu'))
model.add(Dense(15,activation='relu'))
model.add(Dense(4,activation = 'softmax'))
    
model.compile(
              loss='categorical_crossentropy', 
              metrics=['acc'],
              optimizer='adam'
             )

# Model Summary
model.summary()
history = model.fit(x_train,y_train,epochs=200,batch_size=32,validation_data=(x_val,y_val))
model.save("classifier_model.h5")

evaluate = model.evaluate(x_val,y_val)
outp = { 0:'black_woman',1:'black_man',2:'white_woman',3:'white_man'}
img_width, img_height = 256, 256

# load the model we saved
fps = []
preds = []

# add the evaluation results
fps.append("evaluation")
preds.append(evaluate)


files = os.listdir("./CUST")
for fil in files:
    path = "CUST/"+fil
    img = image.load_img(path, target_size=(img_width, img_height))
    predict = model.predict(np.array(img))
    classes = outp[np.argmax(predict)]
    preds.append(classes)
    fps.append(fil)
    
    

preds.append("break")
preds.append("break")

files = os.listdir("./ORIG")
for fil in files:
    path = "ORIG/"+fil
    img = image.load_img(path, target_size=(img_width, img_height))
    predict = model.predict(np.array(img))
    classes = outp[np.argmax(predict)]
    preds.append(classes)
    fps.append(fil)




output = [fps,preds]
output = pd.DataFrame(output)
output.to_csv("cust_preds.csv")
